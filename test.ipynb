{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "from cvzone.ClassificationModule import Classifier\n",
    "import numpy as np\n",
    "from collections import Counter \n",
    "import math\n",
    "import time\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector=HandDetector(maxHands=1)\n",
    "classifier=Classifier(\"Model/new_keras_model.h5\",\"Model/labels.txt\")\n",
    "\n",
    "offset=20\n",
    "imgSize=300\n",
    "\n",
    "# folder=\"Data/Z\"\n",
    "counter=0\n",
    "\n",
    "labels=[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\"]\n",
    "\n",
    "l = []\n",
    "res = ''\n",
    "letters = cv2.imread('The_26_letters.jpg')\n",
    "cv2.imshow(\"The 26 letters\", letters)\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    img = cv2.flip(img, 1)\n",
    "    imgOutput = img.copy()\n",
    "    hands, img=detector.findHands(img)\n",
    "    if hands:\n",
    "        hand=hands[0]\n",
    "        x, y, w, h=hand['bbox']\n",
    "        imgWhite=np.ones((imgSize,imgSize,3), np.uint8)*255\n",
    "        imgCrop = img[y-offset:y+h+offset, x-offset:x + w+offset]\n",
    "\n",
    "        imgCropShape=imgCrop.shape\n",
    "\n",
    "        aspectRatio=h/w\n",
    "\n",
    "        if aspectRatio > 1:\n",
    "            k=imgSize/h\n",
    "            wCal=math.ceil(k*w)\n",
    "            if imgCrop.size==0:\n",
    "                pass\n",
    "                # print(\"Image is empty.\")\n",
    "            else:\n",
    "                imgResize=cv2.resize(imgCrop, (wCal, imgSize))\n",
    "                imgResizeShape=imgResize.shape\n",
    "                wGap=math.ceil((imgSize-wCal)/2)\n",
    "                imgWhite[:, wGap: wCal + wGap]=imgResize\n",
    "                prediction, index=classifier.getPrediction(imgWhite)\n",
    "            # print(prediction,index)\n",
    "            \n",
    "        else:\n",
    "            k=imgSize/w\n",
    "            hCal=math.ceil(k*h)\n",
    "            if imgCrop.size==0:\n",
    "                pass\n",
    "                # print(\"Image is empty.\")\n",
    "            else:\n",
    "                imgResize=cv2.resize(imgCrop, (imgSize, hCal))\n",
    "                imgResizeShape=imgResize.shape\n",
    "                hGap=math.ceil((imgSize-hCal)/2)\n",
    "                imgWhite[hGap: hCal + hGap, :]=imgResize\n",
    "                prediction, index=classifier.getPrediction(imgWhite)\n",
    "        \n",
    "        cv2.putText(imgOutput, labels[index], (x,y-20), cv2.FONT_HERSHEY_COMPLEX, 2, (255, 0, 255), 2)\n",
    "        cv2.putText(imgOutput, res, (0,30), cv2.FONT_HERSHEY_COMPLEX, 2, (0, 0, 255), 2)\n",
    "        l.append(labels[index])\n",
    "        if len(l)==50:\n",
    "            d = sorted(Counter(l).items())\n",
    "            res += d[0][0]\n",
    "            l.clear()\n",
    "        cv2.rectangle(imgOutput, (x-offset, y-offset), (x + w+offset, y + h+offset), (255, 0, 255), 4)\n",
    "        # if imgCrop.shape[0] > 0 and imgCrop.shape[1] > 0 and imgWhite.shape[0] > 0 and imgWhite.shape[1] > 0:\n",
    "        #     cv2.imshow(\"ImageCrop\", imgCrop)\n",
    "        #     cv2.imshow(\"ImageWhite\", imgWhite)\n",
    "    cv2.imshow(\"Image\", imgOutput)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
